---
- name: Check current Helm version (if any)
  ansible.builtin.command: helm version --short
  register: helm_version
  failed_when: false
  delegate_to: node1
  run_once: true

- name: Download Helm install script
  ansible.builtin.get_url:
    url: https://raw.githubusercontent.com/helm/helm/main/scripts/get-helm-3
    dest: /tmp/get_helm.sh
    mode: '0755'
  delegate_to: node1
  run_once: true

- name: Run Helm install script for v3.17.3
  environment:
    HELM_INSTALL_VERSION: "v3.17.3"
  ansible.builtin.command: /tmp/get_helm.sh
  when: helm_version.stdout is not defined or 'v3.17.3' not in helm_version.stdout
  delegate_to: node1
  run_once: true

- name: Create installation directory on control plane
  ansible.builtin.file:
    path: "{{ install_dir }}"
    state: directory
    mode: '0755'
  delegate_to: node1
  run_once: true

- name: Create NVIDIA RuntimeClass manifest on control plane
  ansible.builtin.copy:
    src: "nvidia-runtime.yml"
    dest: "{{ install_dir }}/nvidia-runtime-class.yml"
  delegate_to: node1
  run_once: true

- name: Apply NVIDIA RuntimeClass from control plane
  kubernetes.core.k8s:
    state: present
    src: "{{ install_dir }}/nvidia-runtime-class.yml"
  delegate_to: node1
  run_once: true

- name: Label GPU nodes for NVIDIA support
  kubernetes.core.k8s:
    state: patched
    kind: Node
    name: "{{ inventory_hostname }}"
    definition:
      metadata:
        labels:
          allow-nvdp: "true"
          nvidia.com/gpu.present: "true"
  delegate_to: node1
  when: has_gpu

- name: Add NVIDIA Device Plugin Helm repository
  kubernetes.core.helm_repository:
    name: nvdp
    repo_url: https://nvidia.github.io/k8s-device-plugin
  delegate_to: node1
  run_once: true

- name: Update Helm repositories
  command: helm repo update
  changed_when: true
  delegate_to: node1
  run_once: true

- name: Check for required GPU node labels on all GPU nodes
  ansible.builtin.shell: >
    kubectl get nodes -l allow-nvdp=true -o json | jq -r '.items | length'
  register: labeled_gpu_nodes_count
  changed_when: false
  delegate_to: node1
  run_once: true

- name: Get total GPU nodes count
  ansible.builtin.shell: >
    kubectl get nodes -l nvidia.com/gpu.present=true -o json | jq -r '.items | length'
  register: total_gpu_nodes_count
  changed_when: false
  delegate_to: node1
  run_once: true

- name: Get list of labeled GPU nodes
  ansible.builtin.shell: >
    kubectl get nodes -l allow-nvdp=true -o jsonpath='{range .items[*]}{.metadata.name}{"\n"}{end}'
  register: labeled_nodes_list
  changed_when: false
  delegate_to: node1
  run_once: true

- name: Display GPU node labeling status
  ansible.builtin.debug:
    msg: |
      GPU Node Labeling Status:
      - Total GPU nodes: {{ total_gpu_nodes_count.stdout }}
      - Labeled nodes: {{ labeled_gpu_nodes_count.stdout }}
      - Nodes with allow-nvdp=true:
      {{ labeled_nodes_list.stdout_lines | join('\n      ') if labeled_nodes_list.stdout_lines | length > 0 else '      None' }}
  delegate_to: node1
  run_once: true

- name: Set labels_ready flag
  ansible.builtin.set_fact:
    labels_ready: "{{ (labeled_gpu_nodes_count.stdout | int) > 0 }}"
  delegate_to: node1
  run_once: true

- name: Verify all GPU nodes are labeled
  ansible.builtin.fail:
    msg: "Not all GPU nodes are labeled! Expected {{ total_gpu_nodes_count.stdout }} but only {{ labeled_gpu_nodes_count.stdout }} nodes have allow-nvdp=true"
  when: labeled_gpu_nodes_count.stdout != total_gpu_nodes_count.stdout
  delegate_to: node1
  run_once: true

- name: Install NVIDIA Device Plugin with CDI
  kubernetes.core.helm:
    name: nvdp
    chart_ref: nvdp/nvidia-device-plugin
    release_namespace: nvidia-device-plugin
    create_namespace: true
    chart_version: "{{ nvdp_version }}"
    values:
      runtimeClassName: nvidia
      deviceListStrategy: cdi-cri
      nvidiaDriverRoot: "/"
      nodeSelector:
        allow-nvdp: "true"
    state: present
  when: labels_ready | bool
  delegate_to: node1
  run_once: true

- name: Wait for NVIDIA Device Plugin pods to be ready
  ansible.builtin.command: kubectl -n nvidia-device-plugin wait --for=condition=ready pod -l app.kubernetes.io/instance=nvdp --timeout=300s
  delegate_to: node1
  run_once: true
  register: nvdp_wait
  changed_when: false
  failed_when: false

- name: Get NVIDIA Device Plugin logs
  ansible.builtin.command: kubectl -n nvidia-device-plugin logs -l app.kubernetes.io/instance=nvdp --tail=50
  delegate_to: node1
  run_once: true
  register: nvdp_logs
  changed_when: false

- name: Display NVIDIA Device Plugin logs
  ansible.builtin.debug:
    msg: "{{ nvdp_logs.stdout_lines }}"
